{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "\n",
    "  def __init__(self, n_arms, probabilities, bids, average_number_of_clicks, average_cum_daily_cost,noise_clicks,noise_cost):\n",
    "    self.n_arms = n_arms                                            # number of prices\n",
    "    self.probabilities = probabilities                              # conversion rates for every price/arm\n",
    "    self.bids = bids                                                # bids\n",
    "    self.average_number_of_clicks = average_number_of_clicks        # curve of average number of clicks (y = f(bids))\n",
    "    self.average_cum_daily_cost = average_cum_daily_cost            # curve of cumulative daily cost (y = g(bids))\n",
    "    self.noise_clicks = noise_clicks                                # gaussian noise for the average number of clicks sampling\n",
    "    self.noise_cost = noise_cost                                    # gaussian noise for the cumulative daily cost sampling\n",
    "\n",
    "  # daily rewards\n",
    "  def bidding_round(self, pulled_bid):\n",
    "    clicks = int(np.random.normal(self.average_number_of_clicks(self.bids[pulled_bid]),self.noise_clicks))        # number of people that click on the ad\n",
    "    reward_click = clicks if clicks >= 0 else 0\n",
    "    costs = np.random.normal(self.average_cum_daily_cost(self.bids[pulled_bid]),self.noise_cost)                  # cumulative daily cost\n",
    "    reward_cost = costs if costs > 0 else 0\n",
    "\n",
    "    return reward_click, reward_cost\n",
    "\n",
    "  def pricing_round(self, pulled_price):\n",
    "    reward_price = np.random.binomial(1,self.probabilities[pulled_price])                         # number of people that buy once they clicked\n",
    "    return reward_price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "  def __init__(self,n_arms):\n",
    "    self.n_arms = n_arms\n",
    "    self.t = 0                                              # current round value\n",
    "    self.rewards_per_arm = x = [[] for i in range(n_arms)]  # value of collected rewards for each round and for each arm\n",
    "    self.collected_rewards = np.array([])                   # values of collected rewards for each round\n",
    "\n",
    "  # function that updates the observation's list once the reward is returned by the environment\n",
    "  def update_observations(self, pulled_arm, reward):\n",
    "    self.rewards_per_arm[pulled_arm].append((reward, self.t))\n",
    "    self.collected_rewards = np.append(self.collected_rewards,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS_Pricing_Learner(Learner): # Thompson-Sampling (reward: number of conversions; actual_reward:  price*conversion_rate)\n",
    "  def __init__(self,n_arms,prices):\n",
    "    super().__init__(n_arms)                    # number of prices\n",
    "    self.beta_parameters = np.ones((n_arms,2))  # parameters of beta distributions\n",
    "    self.prices = prices                        # prices (array)\n",
    "\n",
    "    #self.empirical_means = np.zeros(n_arms)\n",
    "\n",
    "  def pull_arm(self):\n",
    "    if(self.t < self.n_arms):\n",
    "      return self.t\n",
    "    sampled = np.random.beta(self.beta_parameters[:,0],self.beta_parameters[:,1])*self.prices\n",
    "    idx = np.argmax(sampled)\n",
    "    #return idx, sampled[idx]\n",
    "    return idx\n",
    "\n",
    "  # update parameters each time a reward in {0,1} is observed\n",
    "  def update(self,pulled_arm, reward):\n",
    "    self.t += 1\n",
    "    self.update_observations(pulled_arm,reward*self.prices[pulled_arm])\n",
    "    self.beta_parameters[pulled_arm,0] = self.beta_parameters[pulled_arm,0] + reward\n",
    "    self.beta_parameters[pulled_arm,1] = self.beta_parameters[pulled_arm,1] + 1 - reward\n",
    "\n",
    "    #self.empirical_means[pulled_arm] = (self.empirical_means[pulled_arm]*(len(self.rewards_per_arm[pulled_arm]) - 1) + reward*self.prices[pulled_arm] ) / len(self.rewards_per_arm[pulled_arm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SW_UCB_Pricing_Learner(Learner): # UCB1 (reward: number of conversions; actual_reward:  price*conversion_rate)\n",
    "  def __init__(self,n_arms,prices, tau=int(np.sqrt(365))):\n",
    "    super().__init__(n_arms)                              # number of arms/prices\n",
    "    self.empirical_means = np.zeros(n_arms)               # mean reward for each arm (conversion rate)\n",
    "    self.confidence = np.zeros(n_arms)                    # confidence bound for each arm\n",
    "    self.prices = prices                                  # prices (array)\n",
    "    self.tau = tau                                        # parameter for the confidence bound\n",
    "\n",
    "  def count_elements_in_range(data, time, tau=0):\n",
    "    count = 0\n",
    "    if time - tau < 0:\n",
    "      tau = 0\n",
    "    for reward, t in data:\n",
    "        if t >= time - tau and t <= time:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "  def pull_arm(self):\n",
    "    if(self.t < self.n_arms):\n",
    "      return self.t\n",
    "    \n",
    "    for a in range(self.n_arms):\n",
    "      if self.count_elements_in_range(self.rewards_per_arm[a], self.t - 1, self.tau) == 0:\n",
    "        return a\n",
    "\n",
    "    upper_bound = self.empirical_means + self.confidence\n",
    "    pulled_arm = np.random.choice(np.where(upper_bound == upper_bound.max())[0])\n",
    "    return pulled_arm\n",
    "\n",
    "  def update(self, pulled_arm, reward):\n",
    "    self.t += 1\n",
    "    self.update_observations(pulled_arm, reward*self.prices[pulled_arm])\n",
    "    self.empirical_means[pulled_arm] = (self.empirical_means[pulled_arm]*(len(self.rewards_per_arm[pulled_arm][0]) - 1 - self.tau) + reward*self.prices[pulled_arm] ) / len(self.rewards_per_arm[pulled_arm][0])\n",
    "    for a in range(self.n_arms):\n",
    "      self.confidence[a] = self.prices[a]*np.sqrt(2*np.log(self.t)/self.count_elements_in_range(self.rewards_per_arm[a], self.t-1, self.tau)) if self.count_elements_in_range(self.rewards_per_arm[a], self.t-1, self.tau) > 0 else 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CD_UCB_Pricing_Learner(Learner): # UCB1 (reward: number of conversions; actual_reward:  price*conversion_rate)\n",
    "  def __init__(self,n_arms,prices):\n",
    "    super().__init__(n_arms)                              # number of arms/prices\n",
    "    self.empirical_means = np.zeros(n_arms)               # mean reward for each arm (conversion rate)\n",
    "    self.confidence = np.zeros(n_arms)                    # confidence bound for each arm\n",
    "    self.prices = prices                                  # prices (array)\n",
    "\n",
    "  def pull_arm(self):\n",
    "    if(self.t < self.n_arms):\n",
    "      return self.t\n",
    "    upper_bound = self.empirical_means + self.confidence\n",
    "    pulled_arm = np.random.choice(np.where(upper_bound == upper_bound.max())[0])\n",
    "    #return pulled_arm, upper_bound[pulled_arm]\n",
    "    #return pulled_arm, self.empirical_means[pulled_arm]\n",
    "    return pulled_arm\n",
    "\n",
    "  def update(self, pulled_arm, reward):\n",
    "    self.t += 1\n",
    "    self.update_observations(pulled_arm, reward*self.prices[pulled_arm])\n",
    "    self.empirical_means[pulled_arm] = (self.empirical_means[pulled_arm]*(len(self.rewards_per_arm[pulled_arm]) - 1) + reward*self.prices[pulled_arm] ) / len(self.rewards_per_arm[pulled_arm])\n",
    "    for a in range(self.n_arms):\n",
    "      self.confidence[a] = self.prices[a]*np.sqrt(2*np.log(self.t)/len(self.rewards_per_arm[a])) if len(self.rewards_per_arm[a]) > 0 else 1e3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
